normalized_data = clean_normalization_min_max(cleaned_data);
set.seed(42);
best_features_data = select_features(normalized_data ,24)
set.seed(10)
best_features_data  = normalized_data [ c ( select_features(normalized_data ,24) ,"class")]
set.seed(20)
best_features_data  = normalized_data [ c ( select_features(normalized_data ,24) ,"class")]
set.seed(40)
best_features_data  = normalized_data [ c ( select_features(normalized_data ,24) ,"class")]
set.seed(46)
best_features_data  = normalized_data [ c ( select_features(normalized_data ,24) ,"class")]
set.seed(200)
best_features_data  = normalized_data [ c ( select_features(normalized_data ,24) ,"class")]
set.seed(220)
best_features_data  = normalized_data [ c ( select_features(normalized_data ,24) ,"class")]
names(best_features_data)
idx = sample(seq(1, 3), size = nrow(best_features_data), replace = FALSE, prob = c(.6, .2, .2)
)
idx = sample(seq(1, 3), size = nrow(best_features_data), replace = T, prob = c(.6, .2, .2) )
train_set = best_features_data[idx==1,]
cv_set = best_features_data[idx==2,]
test_set =best_features_data[idx ==3 ,]
featue_names =names(train_set)
featue_names = names(train_set) [ ! names(train_set) %in% "class"]
features_formula = paste(featue_names,collapse = "+")
features_formula
r_tree_formula = as.formula(paste("class",features_formula,sep = "~"))
r_tree_formula
rf_model = randomForest(r_tree_formula,data = train_set , ntree=500 )
rf_model
plot(rf_model)
pree= predict(rf_model,newdata = cv_set)
pree
table(pree,cv_set$class)
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = cv_set , positive = T )
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = cv_set  )
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = cv_set$class , positive = T )
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = cv_set$class  )
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = cv_set$class ,positive = 'yes' )
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = cv_set$class)
rmse
library(rmse)
rf_model = randomForest(r_tree_formula,data = train_set , ntree=600 )
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = cv_set$class)
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = test_set$class)
confusionMatrix( predict(rf_model,newdata = test_set) ,reference = test_set$class)
rf_model = randomForest(r_tree_formula,data = train_set , ntree=200 )
confusionMatrix( predict(rf_model,newdata = test_set) ,reference = test_set$class)
rf_model = randomForest(r_tree_formula,data = train_set , ntree=200 )
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = cv_set$class)
rf_model = randomForest(r_tree_formula,data = train_set , ntree=300 )
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = cv_set$class)
rf_model = randomForest(r_tree_formula,data = train_set , ntree=700 )
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = cv_set$class)
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = test_set$class)
confusionMatrix( predict(rf_model,newdata = test_set) ,reference = test_set$class)
rf_model = randomForest(r_tree_formula,data = train_set , ntree=100 )
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = cv_set$class)
rf_model = randomForest(r_tree_formula,data = train_set , ntree=200 )
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = cv_set$class)
summary(rf_model)
confusionMatrix( predict(rf_model,newdata = test_set) ,reference = test_set$class)
rf_model = randomForest(r_tree_formula,data = train_set , ntree=700 )
confusionMatrix( predict(rf_model,newdata = test_set) ,reference = test_set$class)
cf_matr= confusionMatrix( predict(rf_model,newdata = test_set) ,reference = test_set$class)
cf_matr$positive
cf_matr$overall
cf_matr$overall[0]
cf_matr$overall[1]
library(reprtree)
install.packages(reprtree)
download.packages(reprtree)
library(reprtree)
install.packages("reprtree")
getTree(rf_model)
ptions(repos='http://cran.rstudio.org')
have.packages <- installed.packages()
cran.packages <- c('devtools','plotrix','randomForest','tree')
to.install <- setdiff(cran.packages, have.packages[,1])
if(length(to.install)>0) install.packages(to.install)
library(devtools)
if(!('reprtree' %in% installed.packages())){
install_github('araastat/reprtree')
}
for(p in c(cran.packages, 'reprtree')) eval(substitute(library(pkg), list(pkg=p)))
library(reprtree)
reprtree:::plot.getTree(rf_model)
reprtree:::plot.reprtree(rf_model)
reprtree:::plot.getTree(rf_model)
plot(rf_model)
plot(rf_model)
ggplot(rf_model)
plot(rf_model)
plot(rf_model)
par(mar = rep(2, 4))
plot(rf_model)
plot(rf_model)
graphics.off()
plot(rf_model)
qplot(rf_model)
plot(rf_model)
rf_model = randomForest(r_tree_formula,data = train_set , ntree=600 )
confusionMatrix( predict(rf_model,newdata = cv_set) ,reference = cv_set$class)
library(neuralnet)
nn = neuralnet(formula = r_tree_formula, data= test_set ,hidden = c(5,5,5),linear.output = T  );
r_tree_formula
nn = neuralnet(formula = r_tree_formula, data= test_set ,hidden = c(5,5,5),linear.output = T  );
n_train= model.matrix(r_tree_formula,data =train_set)
n_train
features_formula
n_train= model.matrix( c( "~class" ,features_formula ) ,data =train_set)
n_train= model.matrix( paste("~class",features_formula,sep="+" ) ,data =train_set)
n_train= model.matrix( paste("\~class",features_formula,sep="+" ) ,data =train_set)
n_train= model.matrix( paste("class",features_formula,sep="+" ) ,data =train_set)
featue_names
features_formula
n_train= model.matrix( ~ class + specific_gravity+hemoglobin+serum_creatinine+packed_cell_volume+albumin+red_blood_cell_count+diabetes_mellitus+hypertension+blood_glucose_random ,data =train_set)
n_train
nn = neuralnet(formula = r_tree_formula, data= n_train ,hidden = c(5,5,5),linear.output = T  );
str(train_set)
n_train = train_set
n_train$hypertension = as.integer(n_train$hypertension)
n_train$diabetes_mellitus = as.integer(n_train$diabetes_mellitus)
n_train
n_train$class = as.integer(n_train$class)
str(n_train)
nn = neuralnet(formula = r_tree_formula, data= n_train ,hidden = c(5,5,5),linear.output = T  );
confusionMatrix( predict(nn,newdata = cv_set) ,reference = cv_set$class)
pred = compute(nn ,cv_set$class)
pred = compute(nn , as.integer( cv_set$class)  )
pred = compute(nn , n_train$class )
pred = compute(nn , n_train[,1:9  ] )
pred$net.result
confusionMatrix( pred ,reference = as.integer( cv_set$class) )
confusionMatrix( data = as.factor( pred) ,reference = as.factor( cv_set$class) )
confusionMatrix( data = factor( pred) ,reference = factor( cv_set$class),positive='1' )
pred
nn = neuralnet(formula = r_tree_formula, data= n_train ,hidden = c(5,5,5),linear.output = T  );
pred = compute(nn, cv_set [,1:9 ])
n_cv_set =cv_set
n_cv_set$class = as.numeric( n_cv_set)
n_cv_set$class = as.integer( n_cv_set)
n_cv_set$class = as.integer( n_cv_set$class)
str( n_cv_set)
n_cv_set$diabetes_mellitus = as.integer(n_cv_set$diabetes_mellitus)
n_cv_set$hypertension = as.integer(n_cv_set$hypertension)
pred = compute(nn, cv_set [,1:9 ])
pred = compute(nn, n_cv_set [,1:9 ])
head(pred$net.result)
table(n_cv_set ,   pred$net.result)
library(nnet)
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= c(5,5,5) );
nn_model = nnet(formula =r_tree_formula , data = train_set ,size=10);
nn = neuralnet(formula = r_tree_formula, data= train_set ,hidden = c(5,5,5),linear.output = F  );
plot(nn_model)
confusionMatrix( predict(nn_model,newdata = cv_set) ,reference = cv_set$class)
yhat <- predict(nn_model, cv_set[,1:9], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,10])
nn = neuralnet(formula = r_tree_formula, data= n_train ,hidden = c(5,5,5),linear.output = F  );
c_m = compute(nn , n_cv_set[,1:9])
confusionMatrix(c_m ,n_cv_set[,9])
confusionMatrix(c_m ,n_cv_set[,10])
head(c_m)
str(c_m)
confusionMatrix(c_m$net.result ,n_cv_set[,10])
str(c_m$net.result)
ff = as.factor(c_m$net.result)
ff
head(c_m$net.result)
summary(c_m$net.result)
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 5 );
yhat <- predict(nn_model, cv_set[,1:9], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,10])
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 15 );
yhat <- predict(nn_model, cv_set[,1:9], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,10])
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 2 );
yhat <- predict(nn_model, cv_set[,1:9], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,10])
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 2 );
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 2 );
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 2 );
yhat <- predict(nn_model, cv_set[,1:9], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,10])
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 3 );
yhat <- predict(nn_model, cv_set[,1:9], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,10])
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 2 );
yhat <- predict(nn_model, test_set[,1:9], type = 'class')
confusionMatrix(as.factor(yhat), test_set[,10])
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 2 );
yhat <- predict(nn_model, cv_set[,1:9], type = 'class')
confusionMatrix(as.factor(yhat), test_set[,10])
confusionMatrix(as.factor(yhat), cv_set[,10])
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 5 );
yhat <- predict(nn_model, cv_set[,1:9], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,10])
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 10 );
yhat <- predict(nn_model, cv_set[,1:9], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,10])
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 25 );
yhat <- predict(nn_model, cv_set[,1:9], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,10])
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 5 );
yhat <- predict(nn_model, cv_set[,1:9], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,10])
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 5 );
yhat <- predict(nn_model, test_set[,1:9], type = 'class')
confusionMatrix(as.factor(yhat), test_set[,10])
library(devtools)
source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')
plot.nnet(nn_model)
plot.nnet(nn_model, bias=F.)
plot.nnet(nn_model, bias=F)
plot.nnet(nn_model,wts.only = T)
plot.nnet(nn_model,wts.only = T)
plot.nnet(nn_model)
yhat <- predict(nn_model, test_set[,1:ncol(test_set-1) ], type = 'class')
yhat <- predict(nn_model, test_set[,1:ncol(test_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,ncol(test_set)])
confusionMatrix(as.factor(yhat), test_set[,ncol(test_set)])
svm_model = svm(r_tree_formula, data = train_set , cost=100 ,gamma =1 )
yhat <- predict(svm_model, csv_set[,1:ncol(csv)-1 ], type = 'class')
yhat <- predict(svm_model, csv_set[,1:ncol(csv_set)-1 ], type = 'class')
yhat <- predict(svm_model, cv_set[,1:ncol(cv_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,ncol(cv_set)])
svm_model = svm(r_tree_formula, data = train_set , cost=500 ,gamma =1 )
yhat <- predict(svm_model, cv_set[,1:ncol(cv_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,ncol(cv_set)])
svm_model = svm(r_tree_formula, data = train_set , cost=500 ,gamma =20 )
yhat <- predict(svm_model, cv_set[,1:ncol(cv_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,ncol(cv_set)])
svm_model = svm(r_tree_formula, data = train_set , cost=200 ,gamma =10 )
yhat <- predict(svm_model, cv_set[,1:ncol(cv_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,ncol(cv_set)])
svm_model = svm(r_tree_formula, data = train_set , cost=200 ,gamma =5 )
yhat <- predict(svm_model, cv_set[,1:ncol(cv_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,ncol(cv_set)])
svm_model = svm(r_tree_formula, data = train_set , cost=200 ,gamma =0.5 )
yhat <- predict(svm_model, cv_set[,1:ncol(cv_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,ncol(cv_set)])
svm_model = svm(r_tree_formula, data = train_set , cost=200 ,gamma =10 )
svm_model = svm(r_tree_formula, data = train_set , cost=100 ,gamma =10 )
yhat <- predict(svm_model, cv_set[,1:ncol(cv_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,ncol(cv_set)])
svm_model = svm(r_tree_formula, data = train_set , cost=100 ,gamma =5 )
yhat <- predict(svm_model, cv_set[,1:ncol(cv_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,ncol(cv_set)])
svm_model = svm(r_tree_formula, data = train_set , cost=100 ,gamma =1 )
yhat <- predict(svm_model, cv_set[,1:ncol(cv_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,ncol(cv_set)])
svm_model = svm(r_tree_formula, data = train_set , cost=100 ,gamma =0.5 )
yhat <- predict(svm_model, cv_set[,1:ncol(cv_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), cv_set[,ncol(cv_set)])
yhat <- predict(svm_model, test_set[,1:ncol(test_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), test_set[,ncol(test_set)])
plot(svm_model)
plot(svm_model$kernel)
svm_model = svm(r_tree_formula, data = train_set , cost=100 ,gamma =0.5 )
yhat <- predict(svm_model, test_set[,1:ncol(test_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), test_set[,ncol(test_set)])
svm_model = svm(r_tree_formula, data = train_set , cost=100 ,gamma =1.5 )
yhat <- predict(svm_model, test_set[,1:ncol(test_set)-1 ], type = 'class')
confusionMatrix(as.factor(yhat), test_set[,ncol(test_set)])
nn_model = nnet(formula =r_tree_formula , data = train_set ,size= 5 );
library("randomForest");
library("e1071");
library(caret);
library(nnet);
### load other R files
source("read_data.R");
source("clean_data.R");
source("features_selection.R")
svm_model = svm(r_tree_formula, data = train_set , cost=100 ,gamma =1.5 )
summarize(raw_data_csv)
summary(raw_data_csv)
str(raw_data_csv)
names(test_set)
d4 .* d5
d4 *. d5
d4 . d5
d4 *. d5
a
library("randomForest");
library("e1071");
library(caret);
library(nnet);
### load other R files
source("read_data.R");
source("clean_data.R");
source("features_selection.R")
############ reading the data #####################
raw_data_csv = read_my_data("file.csv");
hist( raw_data_csv$potassium)
source("clean_data.R");
source("read_data.R");
raw_data_csv = read_my_data("file.csv");
head(raw_data_csv$potassium)
head(raw_data_csv$sodium)
raw_data_csv = read_my_data("file.csv");
################## exploring the data ##################
str(raw_data_csv);
summary(raw_data_csv);
###################clean and normalize the data #####################
cleaned_data =   clean_potassuim_out( clean_sodium_out(  clean_missing(raw_data_csv) ) );
normalized_data = clean_normalization_min_max(cleaned_data);
raw_data_csv = read_my_data("file.csv");
################## exploring the data ##################
str(raw_data_csv);
summary(raw_data_csv);
###################clean and normalize the data #####################
cleaned_data =   clean_potassuim_out( clean_sodium_out(  clean_missing(raw_data_csv) ) );
head(cleaned_data$sodium)
head(cleaned_data$sodium,20)
head(cleaned_data$sodium)
normalized_data = clean_normalization_min_max(cleaned_data);
head(normalized_data$sodium)
staight_data = read.csv("straight_forward_results.csv")
branch_free_data = read.csv("branch_free.csv")
micro_optimized = read.csv("micro_opt_results.csv")
library(ggplot2)
results =read.csv("results_file.csv")
summary(results)
results =read.csv("results_file.csv",header = False)
results =read.csv("results_file.csv",header = F)
summary(results)
names(results)= c("sf","time","type")
summary(results)
ggplot(data=results, aes(x= sf  , y=time, group=type, colour=type) +
geom_line() +
geom_point())
results$type = factor(results$type)
ggplot(data=results, aes(x= sf  , y=time, group=type, colour=type) +
geom_line() +
geom_point())
results$type
ggplot(data=results, aes(x= sf  , y=time, group=type, colour=type) +
geom_line() )
ggplot(data=results, aes(x= sf  , y=time, group=type, colour=type) )
ggplot(data=results, aes(x= sf  , y=time, group=type, colour=type)  )+
geom_line() +
geom_point()
ggplot(data=results, aes(x= sf  , y=time, group=type, colour=type)  )+
geom_line() +
geom_point()+xlab("selectivity factor")+ylab("time in seconds")+ggtitle("performance of branch free predicate vs micro optimized predicate")
ggplot(data=results, aes(x= sf  , y=time, group=type, colour=type)  )+
geom_line() +
geom_point()+xlab("selectivity factor")+ylab("time in seconds")+ggtitle("performance of branch free  vs micro optimized predicate")
ggplot(data=results, aes(x= sf  , y=time, group=type, colour=type)  )+
geom_line() +
geom_point()+xlab("selectivity factor")+ylab("time in seconds")+ggtitle("performance of branch free vs micro optimized predicate")
results =read.csv("results_file6.csv",header = F)
names(results)= c("sf","time","type")
source("draw_results.R")
source("draw_results.R")
my_plot
source("draw_results.R")
install.packages("MonetDB.R")
library(MonetDB.R)
conn <- dbConnect(MonetDB.R(), host="localhost", dbname="thcp2", user="monetdb", password="monetdb")
install.packages("RMySQL")
library("RMySQL")
conn <- dbConnect(MonetDB.R(), host="localhost", dbname="thcp2", user="monetdb", password="monetdb")
conn <- dbConnect(MonetDB.R(), host="localhost", dbname="thcp2", user="monetdb", password="monetdb")
conn <- dbConnect(MonetDB.R(), host="localhost", dbname="thcp2", user="monetdb", password="monetdb")
conn <- dbConnect(MonetDB.R(), host="localhost", dbname="thcp2", user="monetdb", password="monetdb")
conn <- dbConnect(MonetDB.R(), host="localhost", dbname="thcp2", user="monetdb", password="monetdb")
conn <- dbConnect(MonetDB.R(), host="localhost", dbname="tpch2", user="monetdb", password="monetdb")
conn <- dbConnect(MonetDB.R(), host="localhost", dbname="tpch2", user="monetdb", password="monetdb")
dbGetQuery(conn,"SELECT 'hello world'")
dbGetQuery(conn,"SELECT count(*) from 'lineitem' ")
dbGetQuery(conn,"SELECT count(*) from lineitem")
dbGetQuery(conn,"select  count * typewidth   from  sys.storage() where table = 'lineitem' and column ='l_shipdate'; ")
a = dbGetQuery(conn,"select  count * typewidth   from  sys.storage() where table = 'lineitem' and column ='l_shipdate'; ")
a
a + 1
l_shipdate = dbGetQuery(conn,"select  count * typewidth   from  sys.storage() where table = 'lineitem' and column ='l_shipdate'; ")
l_shipdate_size = dbGetQuery(conn,"select  count * typewidth   from  sys.storage() where table = 'lineitem' and column ='l_shipdate'; ")
l_discount_size = dbGetQuery(conn,"select  count * typewidth   from  sys.storage() where table = 'lineitem' and column ='l_discount'; ")
l_quantity = dbGetQuery(conn,"select  count * typewidth   from  sys.storage() where table = 'lineitem' and column ='l_quantity'; ")
l_extendedprice = dbGetQuery(conn,"select  count * typewidth   from  sys.storage() where table = 'lineitem' and column ='l_extendedprice'; ")
l_shipdate = NULL
total_data_processed = l_shipdate_size + l_quantity + l_extendedprice + l_discount_size
total_data_processed
q6 = dbGetQuery(conn,"<\ /home/pegasus/Schreibtisch/current task/tpch_2_17_1/dbgen/MonetDB/1-load_data.SF-1.sql ")
q6 = dbGetQuery(conn,"<\ /home/pegasus/Schreibtisch/current task/tpch_2_17_1/dbgen/MonetDB/1-load_data.SF-1.sql ");
q6 = dbGetQuery(conn,"<\ '/home/pegasus/Schreibtisch/current task/tpch_2_17_1/dbgen/MonetDB/1-load_data.SF-1.sql' ");
q6 = dbGetQuery(conn,"<\ '/home/pegasus/Schreibtisch/current task/tpch_2_17_1/dbgen/MonetDB/1-load_data.SF-1.sql'; ");
q6 = dbGetQuery(conn,"'<\' /home/pegasus/Schreibtisch/current task/tpch_2_17_1/dbgen/MonetDB/1-load_data.SF-1.sql; ");
q6 = dbGetQuery(conn,"\< /home/pegasus/Schreibtisch/current task/tpch_2_17_1/dbgen/MonetDB/1-load_data.SF-1.sql; ");
q6 = dbGetQuery(conn," \< /home/pegasus/Schreibtisch/current task/tpch_2_17_1/dbgen/MonetDB/1-load_data.SF-1.sql; ");
q6 = dbGetQuery(conn," '\<' /home/pegasus/Schreibtisch/current task/tpch_2_17_1/dbgen/MonetDB/1-load_data.SF-1.sql; ");
q6 = dbGetQuery(conn," \< /home/pegasus/Schreibtisch/current task/tpch_2_17_1/dbgen/MonetDB/q06.sql ");
q6 = dbGetQuery(conn," '\<' /home/pegasus/Schreibtisch/current task/tpch_2_17_1/dbgen/MonetDB/q06.sql ");
q6= "select
sum(l_extendedprice * l_discount) as revenue
from
lineitem
where
l_shipdate >= date '1994-01-01'
and l_shipdate < date '1994-01-01' + interval '1' year
and l_discount between .06 - 0.01 and .06 + 0.01
and l_quantity < 24; ";
dbGetQuery(conn,q6);
dbGetQuery(conn," delete * from lineitem ");
dbGetQuery(conn," delete * from 'lineitem' ");
dbGetQuery(conn," delete  from 'lineitem' ");
dbGetQuery(conn," delete  from lineitem ");
monetdb.read.csv(conn, "lineitem.tbl", "lineitem",delim="\|");
monetdb.read.csv(conn, "lineitem.tbl", "lineitem",delim="|");
monetdb.read.csv(conn, "lineitem.tbl", "lineitem",delim="|", overwrite=TRUE);
monetdb.read.csv(conn, "lineitem.tbl", "lineitem",delim="|", append=TRUE);
monetdb.read.csv(conn, "lineitem.tbl", "lineitem",delim="|", overwrite=TRUE);
monetdb.read.csv(conn, "lineitem.tbl", "lineitem",delim="|);
""
"
monetdb.read.csv(conn, "lineitem.tbl", "lineitem",delim="|");
monetdb.read.csv(conn, "lineitem.tbl",append=T  ,"lineitem",delim="|");
monetdb.read.csv(conn, "lineitem.tbl", "lineitem",delim="|");
create_table_q ="CREATE TABLE lineitem (
l_orderkey	INT	NOT NULL,
l_partkey	INT	NOT NULL,
l_suppkey	INT	NOT NULL,
l_linenumber	INT	NOT NULL,
l_quantity	DECIMAL(15,2)	NOT NULL,
l_extendedprice	DECIMAL(15,2)	NOT NULL,
l_discount	DECIMAL(15,2)	NOT NULL,
l_tax	DECIMAL(15,2)	NOT NULL,
l_returnflag	CHAR(1)	NOT NULL,
l_linestatus	CHAR(1)	NOT NULL,
l_shipdate	DATE	NOT NULL,
l_commitdate	DATE	NOT NULL,
l_receiptdate	DATE	NOT NULL,
l_shipinstruct	CHAR(25)	NOT NULL,
l_shipmode	CHAR(10)	NOT NULL,
l_comment	VARCHAR(44)	NOT NULL
);"
dbGetQuery(conn,create_table_q);
dbWriteTable(conn,  "lineitem",read.csv("lineitem",sep="|",header="F"),overwrite=TRUE)
dbWriteTable(conn,  "lineitem",read.csv(file = "lineitem.tbl",sep="|",header=F),overwrite=TRUE)
dbGetQuery(conn,create_table_q);
dbWriteTable(conn,  "lineitem",read.csv(file = "lineitem.tbl",sep="|",header=F),append=TRUE)
f = read.csv(file = "lineitem.tbl",sep="|",header=F),append=TRUE)
f = read.csv(file = "lineitem.tbl",sep="|",header=F))
f = read.csv(file = "lineitem.tbl",sep="|",header=F)
head(f)
f = read.csv(file = "lineitem.tbl",sep=c("|","\n"),header=F)
f = read.csv(file = "region.tbl",sep=c("|","\n"),header=F)
head(f)
f = read.csv(file = "region.tbl",sep=c("|"," "),header=F)
head(f)
f = read.csv(file = "region.tbl",sep=c("|\n"),header=F)
f = read.csv(file = "region.tbl",sep="|\n",header=F)
f = read.csv(file = "region.tbl",sep="|")
head(f)
f = read.csv(file = "region.tbl",sep=c("|"," ","\n") )
f = read.csv(file = "region.tbl",sep=c("|"," ","\n"),header = F )
f = read.csv(file = "region.tbl",sep=("|","\n")  )
f = read.csv(file = "region.tbl",sep=("|"), blank.lines.skip=T )
f = read.csv(file = "region.tbl",sep=("|"), strip.white=T )
f = read.csv(file = "region.tbl",sep=("|"), skipNul=T )
head(f)
f = read.csv(file = "region.tbl",sep=("|"), allowEscapes = T )
f = read.csv(file = "lineitem.tbl",sep="|",header=F)
head(f[;1:ncol(f)  ])
head() f[ncol(F)]
head(f[ncol(f)])
f[ncol(f)] = NULL
dbWriteTable(conn,  "lineitem",f,append=TRUE)
f=NULL
gc()
save.image("~/vvv.RData")
f = read.csv(file = "lineitem.tbl", header = F )
f = NULL
gc()
setwd("~/r_monetdb_benchmark")
#install.packages("tictoc");
#install.packages("MonetDB.R");
#install.packages("RMySQL");
library(tictoc);
library(MonetDB.R);
library("RMySQL");
source("config.R");
conn <- dbConnect(MonetDB.R(), host=hostname, dbname=dbname, user=username, password=password);
for(sf in seq(from = start_scale_factor, to = end_scale_scale_factor, by = scale_factor_increment)) {
current_scale_factor = sf;
source("sql_queries.R");
throughtput_container =c();
for(i in 1:total_num_iteration) {
dbGetQuery(conn,query_create_tables);
dbGetQuery(conn,query_load_tables);
l_shipdate_size = dbGetQuery(conn,"select  count * typewidth   from  sys.storage() where table = 'lineitem' and column ='l_shipdate'; ");
l_discount_size = dbGetQuery(conn,"select  count * typewidth   from  sys.storage() where table = 'lineitem' and column ='l_discount'; ");
l_quantity = dbGetQuery(conn,"select  count * typewidth   from  sys.storage() where table = 'lineitem' and column ='l_quantity'; ");
l_extendedprice = dbGetQuery(conn,"select  count * typewidth   from  sys.storage() where table = 'lineitem' and column ='l_extendedprice'; ");
total_data_processed = l_shipdate_size + l_quantity + l_extendedprice + l_discount_size;
total_data_processed = total_data_processed / (1000 * 1000);
tic()
dbGetQuery(conn,query_tpch_6);
exectime <- toc()
exectime <- exectime$toc - exectime$tic
curr_throughput = total_data_processed / exectime;
throughtput_container =  c(as.numeric(curr_throughput),throughtput_container);
csv_line =paste(sf, i, total_data_processed, exectime, curr_throughput,
sep = ",", collapse = "\n");
write(csv_line , file = path_to_log_file, append = TRUE);
dbGetQuery(conn,query_drop_tables);
}
result_line = paste(sf, median(throughtput_container),
sep = ",", collapse = "\n");
write(result_line , file = path_to_results, append = TRUE);
}
